<!DOCTYPE html>
<html>
	<head>
		<title>Gender and Google Translate</title>
		<link rel="stylesheet" href="style.css"/>
		<meta name="viewport" content="width=device-width, initial-scale=1">
		<meta property="og:title" content="Gender and Google Translate" />
		<meta property="og:description" content="a brief exploration" />
	</head>
	<body>
		<p>I am in Cuba visiting my good friend Isabel. She is female. My Spanish is not very good, and so sometimes I use Google Translate to look up how to say things. I noticed something not totally surprising about Google Translate.</p>
		<h1><img src="Screenshot_20240127-100059_Translate.png"/></h1>
		<p>Google defaults to ameg<b>o</b>, as in <i>male</i> friend. Which in my case is wrong. On its own this is not particularly notable or problematic. Spanish defaults to male in ambiguous situations. For example, if I had two friends, one male, one female, they would be my ameg<b>o</b>s. What I'm more interested in is seeing how adding context will change Google's perception of gender.</p>
		<h1><img src="Screenshot_20240127-102904_Translate.png"/></h1>
		<p>When I include my friend's name Google realizes she's female. Makes sense.</p>
		<h1><img src="Screenshot_20240127-100125_Translate.png"/></h1>
		<h1><img src="Screenshot_20240127-100539_Translate.png"/></h1>
		<p>If I'm in love with my friend, or if my friend is in love with me, he stays male. At least its consistent about defaulting to male. What about with various jobs or roles?</p>
		<h1><img src="Screenshot_20240127-100447_Translate.png"/></h1>
		<h1><img src="Screenshot_20240127-100419_Translate.png"/></h1>
		<h1><img src="Screenshot_20240127-100250_Translate.png"/></h1>
		<h1><img src="Screenshot_20240127-100238_Translate.png"/></h1>
		<p>I caught it! For the vast majority of jobs or role I can think of, even ones that are traditionally female like parent, cook, school teacher, or fortune-teller, Google defaults to male. However it trips up with <q>nurse,</q> which turns my friend into a woman.</p>
		<h1><img src="Screenshot_20240127-101358_Translate.png"/></h1>
		<h1><img src="Screenshot_20240127-101410_Translate.png"/></h1>
		<p>If there's a gendered word in the sentence, Google defaults to that gender. In most cases this makes sense. For example if I say <q>my friend is a man</q> or <q>my friend is male</q> is sees the words <q>man</q> or <q>male</q> and turns my friend into a man. However it gets tripped up in cases of negation. So when I say my friend is <i>not</i> male, google makes my friend male. When I say my friend is not female it makes my friend female. Oops.</p>
		<h1><img src="Screenshot_20240127-100553_Translate.png"/></h1>
		<h1><img src="Screenshot_20240127-100611_Translate.png"/></h1>
		<p>This has the lovely and comical benefit of turning everyone gay. The word <q>dad</q> is so male it turns everyone in the sentence male.</p>
		<h1><img src="Screenshot_20240127-100816_Translate.png"/></h1>
		<h1><img src="Screenshot_20240127-100803_Translate.png"/></h1>
		<p>Only gay kisses according to Google.</p>
		<h1><img src="Screenshot_20240127-100700_Translate.png"/></h1>
		<h1><img src="Screenshot_20240127-100711_Translate.png"/></h1>
		<p>Oh no. This is weird. Being in love with or making out is gay, but in the case of <q>having sex</q> my friend is female in both cases. When it's with my sister it's lesbian sex, but when it's with my brother my friend stays female.</p>
		<h1><img src="Screenshot_20240127-100635_Translate.png"/></h1>
		<h1><img src="Screenshot_20240127-100927_Translate.png"/></h1>
		<p>Apparently anything to do with having sex is so womanly that it breaks the otherwise prevailing norm of defaulting to male in ambiguous cases. I'm a little bit surprised by this as I would guess <q>my friend likes to have sex</q> is talking about a man.<p>
		<h1><img src="Screenshot_20240127-101701_Translate.png"/></h1>
		<p>LOL. Adding the word <q>slutty</q> turns the otherwise male doctor into a woman.</p>
		<p><br>The way Google Translate is made is the Google team gives, for example, two copies of a book to an AI, one in spanish, one in English. It asks the AI to look for patterns between the translations. There isn't someone behind the scenes deciding what Google should do in each case, deciding that all things sexual should be female. Rather, in most books or other media, when a friend has sex, that person is a woman, and the AI has recognized that pattern. Which is to say, whatever biases Google Translate has reflects existing cultural biases.</p>
		<p><br>Just food for thought</p>
	</body>
</html>


